{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import random\n",
    "from shutil import move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_dir ='/teamspace/studios/this_studio/Celebrity Faces Dataset/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/teamspace/studios/this_studio/visual-search-similarity/train'\n",
    "validation_dir = '/teamspace/studios/this_studio/visual-search-similarity/validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata_file = '/teamspace/studios/this_studio/visual-search-similarity/metadata/train_metadata.csv'\n",
    "validation_metadata_file = '/teamspace/studios/this_studio/visual-search-similarity/metadata/validation_metadata.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_and_metadata(dataset_dir, train_dir, validation_dir, train_metadata_file, validation_metadata_file):\n",
    "    # Create directories if they don't exist\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(validation_dir, exist_ok=True)\n",
    "\n",
    "    # Open metadata files for writing\n",
    "    train_metadata = open(train_metadata_file, 'w', newline='')\n",
    "    train_metadata_writer = csv.writer(train_metadata)\n",
    "    train_metadata_writer.writerow(['filename', 'celebrity_name'])  # Header\n",
    "\n",
    "    validation_metadata = open(validation_metadata_file, 'w', newline='')\n",
    "    validation_metadata_writer = csv.writer(validation_metadata)\n",
    "    validation_metadata_writer.writerow(['filename', 'celebrity_name'])  # Header\n",
    "\n",
    "    # Walk through each subdirectory\n",
    "    for root, dirs, files in os.walk(dataset_dir):\n",
    "        if files:  # If there are files in the directory\n",
    "            celebrity_name = os.path.basename(root)  # Get the celebrity name from the directory name\n",
    "            image_files = [file for file in files if file.endswith('.jpg') or file.endswith('.jpeg') or file.endswith('.png')]\n",
    "            random.shuffle(image_files)  # Shuffle the list of images\n",
    "\n",
    "            # Determine split sizes\n",
    "            num_images = len(image_files)\n",
    "            num_train = int(0.7 * num_images)\n",
    "            num_validation = num_images - num_train\n",
    "\n",
    "            # Split images\n",
    "            train_images = image_files[:num_train]\n",
    "            validation_images = image_files[num_train:]\n",
    "\n",
    "            # Move images to respective directories and update metadata\n",
    "            for img in train_images:\n",
    "                src = os.path.join(root, img)\n",
    "                dst = os.path.join(train_dir, celebrity_name, img)\n",
    "                os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
    "                move(src, dst)\n",
    "                train_metadata_writer.writerow([dst, celebrity_name])\n",
    "\n",
    "            for img in validation_images:\n",
    "                src = os.path.join(root, img)\n",
    "                dst = os.path.join(validation_dir, celebrity_name, img)\n",
    "                os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
    "                move(src, dst)\n",
    "                validation_metadata_writer.writerow([dst, celebrity_name])\n",
    "\n",
    "    # Close metadata files\n",
    "    train_metadata.close()\n",
    "    validation_metadata.close()\n",
    "\n",
    "# Call the function to split data and update metadata\n",
    "split_data_and_metadata(dataset_dir, train_dir, validation_dir, train_metadata_file, validation_metadata_file)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
