{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "[[0.3832693  1.4902481  0.35796145 ... 0.71515226 0.07539788 0.35880384]]\n"
     ]
    }
   ],
   "source": [
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "\n",
    "embedding_model = Model(inputs=base_model.input, outputs=GlobalAveragePooling2D()(base_model.output))\n",
    "\n",
    "def get_embedding(model, img_path):\n",
    "    # Load and preprocess the image\n",
    "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=(299, 299))\n",
    "    img_data = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img_data = np.expand_dims(img_data, axis=0)\n",
    "    img_data = tf.keras.applications.inception_v3.preprocess_input(img_data)\n",
    "    \n",
    "    # Get the embedding from the model\n",
    "    embedding = model.predict(img_data)\n",
    "    return embedding\n",
    "\n",
    "# Step 3: Use the Model to Extract Embeddings\n",
    "img_path = '/teamspace/studios/this_studio/visual-search-similarity/train/Angelina Jolie/003_57612506.jpg'  # Path to your image file\n",
    "embedding = get_embedding(embedding_model, img_path)\n",
    "\n",
    "print(embedding)  # Print or use the embedding as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Use the Model to Extract Embeddings\n",
    "img_path_1 = '/teamspace/studios/this_studio/visual-search-similarity/train/Angelina Jolie/003_57612506.jpg'  \n",
    "img_path_2 = '/teamspace/studios/this_studio/visual-search-similarity/train/Angelina Jolie/041_abf5c9cb.jpg'\n",
    "# Path to your image file\n",
    "embedding_1 = get_embedding(embedding_model, img_path_1)\n",
    "embedding_2 = get_embedding(embedding_model, img_path_2)\n",
    "\n",
    "\n",
    "#print(embedding)  # Print or use the embedding as needed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-17 07:04:09.555703: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-17 07:04:10.518571: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (1,2048) and (1,2048) not aligned: 2048 (dim 1) != 1 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 48\u001b[0m\n\u001b[1;32m     45\u001b[0m embedding2 \u001b[38;5;241m=\u001b[39m get_embedding(embedding_model, img_path_2)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Calculate cosine similarity between the two embeddings\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m similarity \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCosine Similarity:\u001b[39m\u001b[38;5;124m\"\u001b[39m, similarity)\n",
      "Cell \u001b[0;32mIn[1], line 29\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[0;34m(v1, v2)\u001b[0m\n\u001b[1;32m     26\u001b[0m v2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(v2)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Calculate the dot product of the vectors\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m dot_product \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Calculate the norm (magnitude) of the vectors\u001b[39;00m\n\u001b[1;32m     32\u001b[0m norm_v1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(v1)\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (1,2048) and (1,2048) not aligned: 2048 (dim 1) != 1 (dim 0)"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Step 1: Create the Embedding Model\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "embedding_model = Model(inputs=base_model.input, outputs=GlobalAveragePooling2D()(base_model.output))\n",
    "\n",
    "# Step 2: Define the Function to Extract Embeddings\n",
    "def get_embedding(model, img_path):\n",
    "    # Load and preprocess the image\n",
    "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=(299, 299))\n",
    "    img_data = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img_data = np.expand_dims(img_data, axis=0)\n",
    "    img_data = tf.keras.applications.inception_v3.preprocess_input(img_data)\n",
    "    \n",
    "    # Get the embedding from the model\n",
    "    embedding = model.predict(img_data)\n",
    "    return embedding\n",
    "\n",
    "def cosine_similarity(v1, v2):\n",
    "    # Ensure the vectors are numpy arrays\n",
    "    v1 = np.array(v1)\n",
    "    v2 = np.array(v2)\n",
    "    \n",
    "    # Calculate the dot product of the vectors\n",
    "    dot_product = np.dot(v1, v2)\n",
    "    \n",
    "    # Calculate the norm (magnitude) of the vectors\n",
    "    norm_v1 = np.linalg.norm(v1)\n",
    "    norm_v2 = np.linalg.norm(v2)\n",
    "    \n",
    "    # Calculate the cosine similarity\n",
    "    cosine_sim = dot_product / (norm_v1 * norm_v2)\n",
    "    \n",
    "    return cosine_sim\n",
    "\n",
    "img_path_1 = '/teamspace/studios/this_studio/visual-search-similarity/train/Angelina Jolie/003_57612506.jpg'  \n",
    "img_path_2 = '/teamspace/studios/this_studio/visual-search-similarity/train/Angelina Jolie/041_abf5c9cb.jpg'\n",
    "\n",
    "# Get embeddings for both images\n",
    "embedding1 = get_embedding(embedding_model, img_path_1)\n",
    "embedding2 = get_embedding(embedding_model, img_path_2)\n",
    "\n",
    "# Calculate cosine similarity between the two embeddings\n",
    "similarity = cosine_similarity(embedding1, embedding2)\n",
    "\n",
    "print(\"Cosine Similarity:\", similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (299, 299, 3)\n"
     ]
    }
   ],
   "source": [
    "img = tf.keras.preprocessing.image.load_img(img_path_1, target_size=(299, 299))\n",
    "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "print(\"Image shape:\", img_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step\n",
      "Embedding 1 shape: (1, 2048)\n",
      "Embedding 2 shape: (1, 2048)\n",
      "Cosine Similarity: 0.5744703412055969\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy.spatial.distance import cosine as cosine_distance\n",
    "\n",
    "# Step 1: Create the Embedding Model\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "embedding_model = Model(inputs=base_model.input, outputs=GlobalAveragePooling2D()(base_model.output))\n",
    "\n",
    "# Step 2: Define the Function to Extract Embeddings\n",
    "def get_embedding(model, img_path):\n",
    "    # Load and preprocess the image\n",
    "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=(299, 299))\n",
    "    img_data = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img_data = np.expand_dims(img_data, axis=0)\n",
    "    img_data = tf.keras.applications.inception_v3.preprocess_input(img_data)\n",
    "    \n",
    "    # Get the embedding from the model\n",
    "    embedding = model.predict(img_data)\n",
    "    return embedding\n",
    "\n",
    "def cosine_similarity(v1, v2):\n",
    "    # Flatten embeddings to 1D arrays\n",
    "    v1 = np.ravel(v1)\n",
    "    v2 = np.ravel(v2)\n",
    "    \n",
    "    # Calculate cosine similarity using scipy's cosine function\n",
    "    similarity = 1 - cosine_distance(v1, v2)\n",
    "    return similarity\n",
    "\n",
    "# Example image paths (replace with your actual image paths)\n",
    "img_path_1 = '/teamspace/studios/this_studio/visual-search-similarity/train/Angelina Jolie/003_57612506.jpg'  \n",
    "img_path_2 = '/teamspace/studios/this_studio/visual-search-similarity/train/Angelina Jolie/041_abf5c9cb.jpg'\n",
    "\n",
    "# Get embeddings for both images\n",
    "embedding1 = get_embedding(embedding_model, img_path_1)\n",
    "embedding2 = get_embedding(embedding_model, img_path_2)\n",
    "\n",
    "# Print embeddings shape (for debugging)\n",
    "print(\"Embedding 1 shape:\", embedding1.shape)\n",
    "print(\"Embedding 2 shape:\", embedding2.shape)\n",
    "\n",
    "# Calculate cosine similarity between the two embeddings\n",
    "similarity = cosine_similarity(embedding1, embedding2)\n",
    "\n",
    "print(\"Cosine Similarity:\", similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step\n",
      "Embedding 1 shape: (1, 2048)\n",
      "Embedding 2 shape: (1, 2048)\n",
      "Euclidean Similarity: 0.0477386451948629\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "import tensorflow as tf\n",
    "\n",
    "# Step 1: Create the Embedding Model\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "embedding_model = Model(inputs=base_model.input, outputs=GlobalAveragePooling2D()(base_model.output))\n",
    "\n",
    "# Step 2: Define the Function to Extract Embeddings\n",
    "def get_embedding(model, img_path):\n",
    "    # Load and preprocess the image\n",
    "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=(299, 299))\n",
    "    img_data = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img_data = np.expand_dims(img_data, axis=0)\n",
    "    img_data = tf.keras.applications.inception_v3.preprocess_input(img_data)\n",
    "    \n",
    "    # Get the embedding from the model\n",
    "    embedding = model.predict(img_data)\n",
    "    return embedding\n",
    "\n",
    "def euclidean_similarity(v1, v2):\n",
    "    # Flatten embeddings to 1D arrays\n",
    "    v1 = np.ravel(v1)\n",
    "    v2 = np.ravel(v2)\n",
    "    \n",
    "    # Calculate Euclidean distance\n",
    "    euclidean_distance = np.sqrt(np.sum((v1 - v2)**2))\n",
    "    \n",
    "    # Calculate Euclidean similarity\n",
    "    euclidean_similarity = 1 / (1 + euclidean_distance)\n",
    "    \n",
    "    return euclidean_similarity\n",
    "\n",
    "# Example image paths (replace with your actual image paths)\n",
    "img_path_1 = '/teamspace/studios/this_studio/visual-search-similarity/train/Angelina Jolie/003_57612506.jpg'  \n",
    "img_path_2 = '/teamspace/studios/this_studio/visual-search-similarity/train/Angelina Jolie/041_abf5c9cb.jpg'\n",
    "\n",
    "# Get embeddings for both images\n",
    "embedding1 = get_embedding(embedding_model, img_path_1)\n",
    "embedding2 = get_embedding(embedding_model, img_path_2)\n",
    "\n",
    "# Print embeddings shape (for debugging)\n",
    "print(\"Embedding 1 shape:\", embedding1.shape)\n",
    "print(\"Embedding 2 shape:\", embedding2.shape)\n",
    "\n",
    "# Calculate Euclidean similarity between the two embeddings\n",
    "similarity = euclidean_similarity(embedding1, embedding2)\n",
    "\n",
    "print(\"Euclidean Similarity:\", similarity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this doesnt work need feature extraction from nn model"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
